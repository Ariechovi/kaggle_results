{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPtq1lJ/G6pltNbk+qlEHnS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ariechovi/kaggle_results/blob/main/kaggle_%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E5%99%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据读入阶段"
      ],
      "metadata": {
        "id": "B_jsuyrFqYs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_path = '/content/drive/MyDrive/My/kaggle_data/digit-recognizer/train.csv'\n",
        "test_path = '/content/drive/MyDrive/My/kaggle_data/digit-recognizer/test.csv'\n",
        "sample_path = '/content/drive/MyDrive/My/kaggle_data/digit-recognizer/sample_submission.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLDgKk9oqZzT",
        "outputId": "51c35642-f2cc-4f67-98bd-3e6802de1f5d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "sample_df = pd.read_csv(sample_path)"
      ],
      "metadata": {
        "id": "iZ7nIhX_r_k_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据准备阶段\n",
        "**目标--把这些数据转成CNN能直接吃的数据格式**\n",
        "- 模型的输入需要什么形状？\n",
        "- 训练集如何存储的？\n",
        "## CNN存储\n",
        "- 输入的格式是`[batch_size, channel, height, width]`\n",
        "- 现在的数据格式是\n",
        "  - 第一列是类别\n",
        "  - 剩下的是像素值\n",
        "## 处理目标\n",
        "- X : [batch_size,1,28,28]，像素值归一化到[0,1]区间\n",
        "- Y：[batch_size]，标签"
      ],
      "metadata": {
        "id": "WblfpOxxHlwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=train_df.drop(columns=['label']).values\n",
        "y_train=train_df['label'].values"
      ],
      "metadata": {
        "id": "xXPMCqTdHnBP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.2,random_state=42)\n",
        "print(X_train.shape, X_val.shape)\n",
        "print(y_train.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFJdJQ-GfSxh",
        "outputId": "d4060f65-8d23-4ead-e2b4-10780383d6d0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33600, 784) (8400, 784)\n",
            "(33600,) (8400,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train/255.0#输入归一化\n",
        "X_train=X_train.reshape(-1,1,28,28)#转换输入形状\n",
        "X_val=X_val/255.0\n",
        "X_val=X_val.reshape(-1,1,28,28)"
      ],
      "metadata": {
        "id": "n-3E8LxBKPR7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor=torch.tensor(X_train,dtype=torch.float32)\n",
        "y_train_tensor=torch.tensor(y_train,dtype=torch.long)#转换成向量\n",
        "X_val_tensor=torch.tensor(X_val,dtype=torch.float32)\n",
        "y_val_tensor=torch.tensor(y_val,dtype=torch.long)"
      ],
      "metadata": {
        "id": "MEWhDd_IoyEb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=TensorDataset(X_train_tensor,y_train_tensor)\n",
        "train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
        "val_dataset=TensorDataset(X_val_tensor,y_val_tensor)\n",
        "val_loader=DataLoader(val_dataset,batch_size=64,shuffle=False)"
      ],
      "metadata": {
        "id": "Hb_qCZdiozLL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images=test_df.values\n",
        "test_images=test_images.reshape(-1,1,28,28) /255.0\n",
        "test_images=torch.tensor(test_images,dtype=torch.float32)\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, images):\n",
        "        self.images = images\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx]\n",
        "\n",
        "test_dataset = TestDataset(test_images)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "Lst3_Df8o7p7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN,self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1,32,kernel_size=3,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "\n",
        "            nn.Conv2d(32,64,kernel_size=3,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*7*7,128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,10)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x=self.conv_layers(x)\n",
        "        x=self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Ostv-jjQo8yP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 判断是否有GPU，若有GPU就使用GPU，否则使用CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Sv5hAW8Yo96a"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=SimpleCNN().to(device)"
      ],
      "metadata": {
        "id": "J0kohaaDpATT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "XoH2FzQ9pBbB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "p7-k1DxSpCrw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=11\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss=0.0\n",
        "\n",
        "    for images,labels in train_loader:\n",
        "        images,labels=images.to(device),labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(images)\n",
        "        loss=loss_fn(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {running_loss/len(train_loader):.4f} | \"\n",
        "          f\"Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.2f}%\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8aT5cWqpD4n",
        "outputId": "13fd1727-45a8-48b2-c7d0-c08ed731df25"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/11] | Train Loss: 0.2549 | Val Loss: 0.0804 | Val Acc: 97.43%\n",
            "Epoch [2/11] | Train Loss: 0.0634 | Val Loss: 0.0503 | Val Acc: 98.37%\n",
            "Epoch [3/11] | Train Loss: 0.0442 | Val Loss: 0.0419 | Val Acc: 98.71%\n",
            "Epoch [4/11] | Train Loss: 0.0326 | Val Loss: 0.0414 | Val Acc: 98.63%\n",
            "Epoch [5/11] | Train Loss: 0.0271 | Val Loss: 0.0395 | Val Acc: 98.67%\n",
            "Epoch [6/11] | Train Loss: 0.0203 | Val Loss: 0.0420 | Val Acc: 98.69%\n",
            "Epoch [7/11] | Train Loss: 0.0152 | Val Loss: 0.0689 | Val Acc: 98.04%\n",
            "Epoch [8/11] | Train Loss: 0.0148 | Val Loss: 0.0513 | Val Acc: 98.40%\n",
            "Epoch [9/11] | Train Loss: 0.0116 | Val Loss: 0.0466 | Val Acc: 98.70%\n",
            "Epoch [10/11] | Train Loss: 0.0105 | Val Loss: 0.0457 | Val Acc: 98.81%\n",
            "Epoch [11/11] | Train Loss: 0.0062 | Val Loss: 0.0474 | Val Acc: 98.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l3TcuJrgGU8C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}