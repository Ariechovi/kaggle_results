{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOk3cwT/qQ/fsS+wxw1AC19",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ariechovi/kaggle_results/blob/main/kaggle_%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E5%99%A82.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据读入阶段"
      ],
      "metadata": {
        "id": "B_jsuyrFqYs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_path = '/content/drive/MyDrive/My/kaggle_data/digit-recognizer/train.csv'\n",
        "test_path = '/content/drive/MyDrive/My/kaggle_data/digit-recognizer/test.csv'\n",
        "sample_path = '/content/drive/MyDrive/My/kaggle_data/digit-recognizer/sample_submission.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLDgKk9oqZzT",
        "outputId": "2281e401-679c-40c0-d4cd-06f4164d47c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor,ToPILImage\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "sample_df = pd.read_csv(sample_path)"
      ],
      "metadata": {
        "id": "iZ7nIhX_r_k_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据准备阶段\n",
        "**目标--把这些数据转成CNN能直接吃的数据格式**\n",
        "- 模型的输入需要什么形状？\n",
        "- 训练集如何存储的？\n",
        "## CNN存储\n",
        "- 输入的格式是`[batch_size, channel, height, width]`\n",
        "- 现在的数据格式是\n",
        "  - 第一列是类别\n",
        "  - 剩下的是像素值\n",
        "## 处理目标\n",
        "- X : [batch_size,1,28,28]，像素值归一化到[0,1]区间\n",
        "- Y：[batch_size]，标签"
      ],
      "metadata": {
        "id": "WblfpOxxHlwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=train_df.drop(columns=['label']).values\n",
        "y_train=train_df['label'].values"
      ],
      "metadata": {
        "id": "xXPMCqTdHnBP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.2,random_state=42)\n",
        "print(X_train.shape, X_val.shape)\n",
        "print(y_train.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFJdJQ-GfSxh",
        "outputId": "bab29a8a-75d3-480d-fa01-e09605836afd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33600, 784) (8400, 784)\n",
            "(33600,) (8400,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train/255.0#输入归一化\n",
        "X_train=X_train.reshape(-1,1,28,28)#转换输入形状\n",
        "X_val=X_val/255.0\n",
        "X_val=X_val.reshape(-1,1,28,28)"
      ],
      "metadata": {
        "id": "n-3E8LxBKPR7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor=torch.tensor(X_train,dtype=torch.float32)\n",
        "y_train_tensor=torch.tensor(y_train,dtype=torch.long)\n",
        "X_val_tensor=torch.tensor(X_val,dtype=torch.float32)\n",
        "y_val_tensor=torch.tensor(y_val,dtype=torch.long)"
      ],
      "metadata": {
        "id": "MEWhDd_IoyEb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义数据增强方法"
      ],
      "metadata": {
        "id": "LProogHNIkqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform=transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0,translate=(0.1,0.1)),\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "val_transform=transforms.ToTensor()\n",
        "\n",
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, images, labels=None, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.to_pil=ToPILImage()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx].squeeze()\n",
        "        image=self.to_pil(image)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label=self.labels[idx]\n",
        "        return image,label\n"
      ],
      "metadata": {
        "id": "J1fF5gjFIms_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=MNISTDataset(X_train_tensor,y_train_tensor,train_transform)\n",
        "val_dataset=MNISTDataset(X_val_tensor,y_val_tensor,val_transform)\n",
        "train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
        "val_loader=DataLoader(val_dataset,batch_size=64,shuffle=False)"
      ],
      "metadata": {
        "id": "Hb_qCZdiozLL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images=test_df.values\n",
        "test_images=test_images.reshape(-1,1,28,28) /255.0\n",
        "test_images=torch.tensor(test_images,dtype=torch.float32)\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, images):\n",
        "        self.images = images\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx]\n",
        "\n",
        "test_dataset = TestDataset(test_images)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "Lst3_Df8o7p7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN,self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1,32,kernel_size=3,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "\n",
        "            nn.Conv2d(32,64,kernel_size=3,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*7*7,128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,10)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x=self.conv_layers(x)\n",
        "        x=self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Ostv-jjQo8yP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 判断是否有GPU，若有GPU就使用GPU，否则使用CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Sv5hAW8Yo96a"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=SimpleCNN().to(device)"
      ],
      "metadata": {
        "id": "J0kohaaDpATT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "XoH2FzQ9pBbB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
      ],
      "metadata": {
        "id": "p7-k1DxSpCrw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss=0.0\n",
        "\n",
        "    for images,labels in train_loader:\n",
        "        images,labels=images.to(device),labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(images)\n",
        "        loss=loss_fn(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {running_loss/len(train_loader):.4f} | \"\n",
        "          f\"Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.2f}%\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8aT5cWqpD4n",
        "outputId": "f7c39ed7-06ce-4b6b-efc2-c9f316010a62"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] | Train Loss: 0.0421 | Val Loss: 0.0299 | Val Acc: 99.06%\n",
            "Epoch [2/20] | Train Loss: 0.0424 | Val Loss: 0.0331 | Val Acc: 98.98%\n",
            "Epoch [3/20] | Train Loss: 0.0364 | Val Loss: 0.0314 | Val Acc: 99.07%\n",
            "Epoch [4/20] | Train Loss: 0.0402 | Val Loss: 0.0261 | Val Acc: 99.18%\n",
            "Epoch [5/20] | Train Loss: 0.0347 | Val Loss: 0.0273 | Val Acc: 99.20%\n",
            "Epoch [6/20] | Train Loss: 0.0346 | Val Loss: 0.0297 | Val Acc: 98.99%\n",
            "Epoch [7/20] | Train Loss: 0.0350 | Val Loss: 0.0294 | Val Acc: 99.05%\n",
            "Epoch [8/20] | Train Loss: 0.0305 | Val Loss: 0.0263 | Val Acc: 99.17%\n",
            "Epoch [9/20] | Train Loss: 0.0341 | Val Loss: 0.0224 | Val Acc: 99.29%\n",
            "Epoch [10/20] | Train Loss: 0.0300 | Val Loss: 0.0263 | Val Acc: 99.26%\n",
            "Epoch [11/20] | Train Loss: 0.0314 | Val Loss: 0.0326 | Val Acc: 98.89%\n",
            "Epoch [12/20] | Train Loss: 0.0293 | Val Loss: 0.0280 | Val Acc: 99.18%\n",
            "Epoch [13/20] | Train Loss: 0.0259 | Val Loss: 0.0251 | Val Acc: 99.26%\n",
            "Epoch [14/20] | Train Loss: 0.0299 | Val Loss: 0.0306 | Val Acc: 99.13%\n",
            "Epoch [15/20] | Train Loss: 0.0279 | Val Loss: 0.0232 | Val Acc: 99.25%\n",
            "Epoch [16/20] | Train Loss: 0.0255 | Val Loss: 0.0233 | Val Acc: 99.29%\n",
            "Epoch [17/20] | Train Loss: 0.0257 | Val Loss: 0.0280 | Val Acc: 99.17%\n",
            "Epoch [18/20] | Train Loss: 0.0267 | Val Loss: 0.0341 | Val Acc: 98.99%\n",
            "Epoch [19/20] | Train Loss: 0.0275 | Val Loss: 0.0311 | Val Acc: 99.08%\n",
            "Epoch [20/20] | Train Loss: 0.0243 | Val Loss: 0.0262 | Val Acc: 99.20%\n"
          ]
        }
      ]
    }
  ]
}